{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate the concept of ensemble learning. With ensemble models, we combine multiple models together to create a more accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "X, y = titanic.drop(columns='survived'), titanic.survived\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class   \n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third  \\\n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline: Integrate preprocessing into the training process\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Number of bootstrap samples and trees in the ensemble\n",
    "n_samples = len(X_train)\n",
    "n_trees = 50\n",
    "\n",
    "def bootstrap_sample(X, y):\n",
    "    indices = np.random.choice(len(X), size=len(X), replace=True)\n",
    "    return X[indices], y[indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([187, 608, 133, 575, 350, 499, 523, 107, 189, 120,\\n       ...\\n       238, 519,  97, 571, 240, 233, 525, 104,  80, 447],\\n      dtype='int32', length=623)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m trees \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_trees):\n\u001b[1;32m----> 4\u001b[0m     X_sample, y_sample \u001b[39m=\u001b[39m bootstrap_sample(X_train, y_train)\n\u001b[0;32m      6\u001b[0m     \u001b[39m# Clone the pipeline for each tree\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     cloned_pipeline \u001b[39m=\u001b[39m Pipeline(steps\u001b[39m=\u001b[39m[(\u001b[39m'\u001b[39m\u001b[39mscaler\u001b[39m\u001b[39m'\u001b[39m, StandardScaler()), (\u001b[39m'\u001b[39m\u001b[39mclf\u001b[39m\u001b[39m'\u001b[39m, DecisionTreeClassifier())])\n",
      "Cell \u001b[1;32mIn[29], line 13\u001b[0m, in \u001b[0;36mbootstrap_sample\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbootstrap_sample\u001b[39m(X, y):\n\u001b[0;32m     12\u001b[0m     indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mlen\u001b[39m(X), size\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(X), replace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mreturn\u001b[39;00m X[indices], y[indices]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5876\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5873\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5874\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5876\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5878\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5880\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:5935\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5933\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5934\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5935\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5937\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5938\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([187, 608, 133, 575, 350, 499, 523, 107, 189, 120,\\n       ...\\n       238, 519,  97, 571, 240, 233, 525, 104,  80, 447],\\n      dtype='int32', length=623)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Train multiple decision trees on different bootstrap samples\n",
    "trees = []\n",
    "for _ in range(n_trees):\n",
    "    X_sample, y_sample = bootstrap_sample(X_train, y_train)\n",
    "    \n",
    "    # Clone the pipeline for each tree\n",
    "    cloned_pipeline = Pipeline(steps=[('scaler', StandardScaler()), ('clf', DecisionTreeClassifier())])\n",
    "    cloned_pipeline.fit(X_sample, y_sample)\n",
    "    trees.append(cloned_pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())]),\n",
       " Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                 ('clf', DecisionTreeClassifier())])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate predictions\n",
    "predictions = np.zeros((len(X_test), n_trees))\n",
    "for tree_index, tree in enumerate(trees):\n",
    "    predictions[:, tree_index] = tree.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [2., 2., 2., ..., 2., 2., 2.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Majority vote\n",
    "y_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=1, arr=predictions.astype('int'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Custom Bagged Trees): 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy\n",
    "print(f\"Accuracy (Custom Bagged Trees): {accuracy_score(y_test, y_pred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
